{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "817221c9",
   "metadata": {},
   "source": [
    "# L9: Building LLM prompts with variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36029c06",
   "metadata": {},
   "source": [
    "In the next cell, you will import the function `print_llm_response` that uses an LLM with an instruction that you provide as a string and displays the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc237f34",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helper_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhelper_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m print_llm_response\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'helper_functions'"
     ]
    }
   ],
   "source": [
    "from helper_functions import print_llm_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3074c1f9",
   "metadata": {},
   "source": [
    "Basically, you can use that function as if you were asking a chatbot. You just need to provide your instructions as a string. For instance, you can ask \"What is the capital of France?\" using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcf6686",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print_llm_response(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e164d69",
   "metadata": {},
   "source": [
    "Let's ask the LLM for the lifestyle description for Otto Matic, whose name is stored in `name`, if he were a `dog_age` years old dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196644ca",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "name = \"Otto Matic\"\n",
    "dog_age = 21/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad18f441",
   "metadata": {
    "height": 79
   },
   "outputs": [],
   "source": [
    "print_llm_response(f\"\"\"If {name} were a dog, he would be {dog_age} years old.\n",
    "Describe what life stage that would be for a dog and what that might \n",
    "entail in terms of energy level, interests, and behavior.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8349cb53",
   "metadata": {},
   "source": [
    "<b>You just used AI with your own variables!</b> You used an LLM with instructions that included variables you defined in this notebook.\n",
    "\n",
    "<b>Congratulations ðŸŽ‰ðŸŽ‰ðŸŽ‰</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51181411",
   "metadata": {},
   "source": [
    "## Variable names restrictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d94522",
   "metadata": {},
   "source": [
    "The following variable names also have some problems. Try to fix them yourself or use the help from the chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af96e951",
   "metadata": {
    "height": 79
   },
   "outputs": [],
   "source": [
    "driver = \"unicorn\"\n",
    "driver's vehicle = \"colorful, asymmetric dinosaur car\"\n",
    "favorite planet = \"Pluto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a3a881",
   "metadata": {},
   "source": [
    "Now, update the next cell with any changes you made in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b7e02c",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "print_llm_response(f\"\"\"Write me a 300 word children's story about a {driver} racing\n",
    "a {driver's vehicle} for the {favorite planet} champion cup.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ec7de7",
   "metadata": {},
   "source": [
    "## Extra practice\n",
    "\n",
    "Try the exercises below to practice the concepts from this lesson. Read the comments in each cell with the instructions for each exercise.\n",
    "\n",
    "<b>Feel free to use the chatbot if you need help.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb2bd26",
   "metadata": {
    "height": 96
   },
   "outputs": [],
   "source": [
    "# Fix this code\n",
    "1favorite-book = \"1001 Ways to Wear a Hat\"\n",
    "\"2002 Ways to Wear a Scarf\" = second_fav_book\n",
    "print(f\"My most favorite book is {1favorite-book}, but I also like {second_fav_book})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407023e6",
   "metadata": {
    "height": 147
   },
   "outputs": [],
   "source": [
    "# Make variables for your favorite game, movie, and food.\n",
    "# Then use print_llm_response to ask the LLM to recommend you\n",
    "# a new song to listen to based on your likes.\n",
    "\n",
    "print_llm_response(f\"\"\"\n",
    "\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
